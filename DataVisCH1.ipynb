{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSohyismbxyP"
      },
      "source": [
        "### **Chapter 1: Introduction**\n",
        "\n",
        "This chapter provides a high-level introduction to data visualization, covering its definition, historical context, relationship to other fields, the process of creating visualizations, and the crucial role of the user and human perception. Data visualization is not just about making data look attractive; it is about making information accessible, understandable, and actionable for a wide range of audiences.\n",
        "\n",
        "---\n",
        "\n",
        "### **1.1 What Is Visualization?**\n",
        "\n",
        "* **Definition**: Visualization is defined as \"the communication of information using graphical representations\". It leverages the human perceptual system's ability to process images in parallel, making it much faster than reading text, which is a sequential process. Visualizations can also be language-independent, like a map or graph understood by people who don't share a common language. For example, a weather map can be interpreted by anyone regardless of their spoken language.\n",
        "\n",
        "* **Visualization in Daily Life**: We encounter visualizations constantly, such as subway maps, weather charts, stock market graphs, 3D medical scans, and assembly instructions. These visualizations help us make decisions quickly, such as choosing a subway route or understanding the weather forecast.\n",
        "\n",
        "* **Why Visualization is Important**: The way data is presented can profoundly impact decision-making. Two key examples from the book highlight this:\n",
        "    1.  **Data Distortion Through Scaling**: The same dataset can be perceived in dramatically different ways depending on how its axes are scaled. As seen in Figure 1.1 of the book, plotting car retail price vs. MPG with different scales can make the data appear as:\n",
        "        * A tight, undifferentiated cluster (when both axes have a large, uniform scale).\n",
        "        * A horizontal linear pattern (when the y-axis is scaled larger).\n",
        "        * A vertical linear pattern (when the x-axis is scaled larger).\n",
        "        * An inversely proportional curve (when the scale is determined by the data's range).\n",
        "        This shows that scaling can be used, intentionally or not, to distort the \"truthful\" representation of data. Always check axis scales when interpreting graphs!\n",
        "    2.  **Human Interpretation of Different Formats**: A 1999 study by Elting et al. presented hypothetical clinical trial data to 34 clinicians using four different formats: a table, pie charts, stacked bar graphs, and an icon display.\n",
        "        * **Results**: The format had a massive impact on the clinicians' ability to make the correct decision to stop the trial.\n",
        "            * **Icon Displays**: 82% correct decisions.\n",
        "            * **Tables**: 68% correct decisions.\n",
        "            * **Pie Charts / Bar Graphs**: 56% correct decisions.\n",
        "        * **Crucial Insight**: This means that up to 25% of patients could have received inappropriate treatment based on data shown in bar or pie charts. Ironically, most clinicians preferred the table and were \"contemptuous of the icon display,\" demonstrating that user preference does not equate to effectiveness. This highlights the importance of choosing the right visualization for the task, not just what users like.\n",
        "\n",
        "---\n",
        "\n",
        "### **1.2 History of Visualization**\n",
        "\n",
        "The use of graphics to convey information has a long and rich history, evolving from simple drawings to complex interactive dashboards.\n",
        "\n",
        "* **Early Visualizations**:\n",
        "    * The earliest examples are **cave paintings**, such as those in the Chauvet Cave from approximately 30,000 years ago, used to record and pass on information. These were the first attempts to visually encode knowledge for future generations.\n",
        "    * **Maps** were essential for travel, commerce, and religion. Ancient maps often reflected the worldview of their creators, mixing geography with mythology.\n",
        "        * The **Peutinger Map** was an early Roman road map that distorted east-west distances to fit on a long scroll, showing the importance of practical design over geographic accuracy.\n",
        "        * The **Hereford Map** is a large medieval map of the world with Jerusalem at its center, mixing real geography with religious and mythical information. This map illustrates how visualizations can reflect cultural values.\n",
        "        * **John Snow's Cholera Map (1854)** is a famous example of thematic cartography. By plotting deaths on a map of London, he identified a strong cluster around the Broad Street water pump. He had the pump handle removed, ending the epidemic and demonstrating a clear geographical link to disease. This is a classic example of visualization leading to actionable insight.\n",
        "    * **Time-Series Visualizations** existed even before the 1600s. An early example from around 1030 by al-Biruni shows the phases of the moon in orbit, demonstrating the use of graphics to represent change over time.\n",
        "\n",
        "* **Abstract & Thematic Graphics**: A critical development was the use of graphics to represent abstract, non-geographical data.\n",
        "    * **William Playfair (late 1700s)** was a pioneer, inventing the line graph and bar chart to show economic data like national debt and trade balances over time. These charts are now standard tools in business and science.\n",
        "    * **Charles Joseph Minard's Map (1869)** of Napoleon's march on Moscow is considered a masterpiece. It brilliantly visualizes six variables on a 2D surface: army size (via the width of the line), geographical location, direction of movement, temperature during the retreat, and time. This map is often cited as one of the best examples of data storytelling.\n",
        "    * **Florence Nightingale (1850s)** used a \"coxcomb\" diagram to show that far more soldiers died from preventable diseases in hospitals than from wounds on the battlefield, compelling sanitary reforms. Her work is a powerful example of how visualization can drive social change.\n",
        "\n",
        "* **Modern Visualization & the Role of Statistics**:\n",
        "    * **Anscombe's Quartet (1973)** is a critical example demonstrating the need for visualization. It comprises four datasets that have nearly identical simple statistical properties (mean, variance, correlation, linear regression). However, when plotted, they reveal four very different structures. This proves that relying on statistics alone can be highly misleading. Always visualize your data before drawing conclusions!\n",
        "\n",
        "---\n",
        "\n",
        "### **1.3 Relationship between Visualization and Other Fields**\n",
        "\n",
        "* **Visualization vs. Computer Graphics**:\n",
        "    * **Computer Graphics (CG)** is the set of tools and techniques used to create images. Its primary focus is often on synthesizing realistic images of 3D objects for art, entertainment, and games. It is the *underpinning* of visualization, providing the technical means to render images.\n",
        "    * **Visualization** uses CG as a medium, but its goal is the **effective communication of data**, not visual realism. It encompasses aspects from other fields like HCI (Human-Computer Interaction), psychology, statistics, and data mining. The underlying models (data vs. geometric objects) and goals (insight vs. realism) are different. For example, a medical scan visualization prioritizes clarity and accuracy over photorealism.\n",
        "\n",
        "* **Scientific Visualization vs. Information Visualization**:\n",
        "    * Historically, a distinction was made between **scientific visualization** (for physical data like MRI scans or fluid flow) and **information visualization** (for abstract data like financial records or networks). Scientific visualization often deals with spatial data, while information visualization handles more abstract relationships.\n",
        "    * This book does not make a strong distinction, treating them as allied fields that both provide representations of data. Increasingly, techniques from both areas are blended in modern applications.\n",
        "\n",
        "---\n",
        "\n",
        "### **1.4 The Visualization Process**\n",
        "\n",
        "Creating a visualization is a multi-stage process, often described as a pipeline. User interaction can occur at any stage, allowing for dynamic exploration and refinement.\n",
        "\n",
        "* **The Core Visualization Pipeline**:\n",
        "    1.  **Data Modeling / Preprocessing**: Raw data is filtered, sampled, and structured into a usable format. This may involve cleaning, normalizing, or transforming data to prepare it for visualization.\n",
        "    2.  **Data Selection**: A subset of the data is chosen for visualization (similar to clipping in graphics). This step helps focus on relevant information and reduce clutter.\n",
        "    3.  **Data to Visual Mappings**: The heart of the process. Data values are mapped to graphical attributes like position, size, shape, and color. Choosing the right mapping is crucial for effective communication.\n",
        "    4.  **View Transformations / Scene Parameters**: The user specifies non-data attributes like camera position, lighting, and color maps. These settings can enhance clarity or highlight specific aspects of the data.\n",
        "    5.  **Rendering**: The computer generates the final image, including axes, keys, and annotations. Good rendering ensures the visualization is both accurate and aesthetically pleasing.\n",
        "\n",
        "* **Role of Perception**: The final stage is the human. A visualization's effectiveness depends on the abilities and limitations of the human visual system.\n",
        "    * **Preattentive Processing**: The visual system can rapidly and accurately detect a limited set of visual properties in parallel, without focused attention. These include differences in color, shape, orientation, and size. For example, a red dot among blue dots is instantly noticeable.\n",
        "    * **Attentive Processing**: Is a slower, serial process that requires focused attention to understand more complex conjunctions of features. For example, finding a specific pattern among many similar shapes.\n",
        "    * Effective visualizations harness preattentive features to draw the user's attention to important aspects of the data, such as outliers or trends.\n",
        "\n",
        "---\n",
        "\n",
        "### **1.5 The Role of Cognition**\n",
        "\n",
        "Cognition goes beyond perception. It involves understanding, remembering, and reasoning about what is seen. A more complete model of the visualization process includes not just the computer's rendering pipeline but also the human's cognitive pipeline, where perception feeds into cognition to produce knowledge. For example, a user may notice a trend in a graph (perception) and then hypothesize about its cause (cognition).\n",
        "\n",
        "---\n",
        "\n",
        "### **1.7 The Scatterplot**\n",
        "\n",
        "The scatterplot is one of the most fundamental and widely used visualization techniques, based on the Cartesian coordinate system. It is especially useful for exploring relationships between two or more variables.\n",
        "\n",
        "* **Process**: It maps data from two dimensions of a dataset to the x and y axes of a plot. Additional data dimensions can be mapped to other visual attributes like the color, size, and shape of the plotted points (or glyphs). For example, a scatterplot of height vs. weight can use color to indicate gender.\n",
        "* **Example from the Book**: The text uses a 2004 vehicle dataset to show the exploratory power of scatterplots.\n",
        "    * Plotting horsepower vs. city MPG for just Toyota vehicles immediately reveals a clear, nearly linear inverse relationship. This helps users quickly spot trends and outliers.\n",
        "    * This generates a hypothesis: for foreign cars, higher horsepower means lower MPG.\n",
        "    * Testing this on Kia vehicles shows a similar pattern, confirming the hypothesis.\n",
        "    * Testing it again on Lexus vehicles shows that the relationship is not as simple, leading to refinement and further exploration. This demonstrates the cycle of exploration and hypothesis testing that visualization enables. Scatterplots are often the first step in data exploration.\n",
        "\n",
        "---\n",
        "\n",
        "### **1.8 The Role of the User**\n",
        "\n",
        "The user's purpose or goal is central to the design of a visualization. Visualizations can be categorized by their intended role:\n",
        "\n",
        "* **Exploration**: The user has a dataset and wants to examine it to find interesting, unknown patterns, features, or outliers. Interactive tools like zooming and filtering are helpful here.\n",
        "* **Confirmation**: The user already has a hypothesis about the data and uses the visualization to confirm or refute it. For example, checking if sales increase after a marketing campaign.\n",
        "* **Presentation**: The user already knows the story in the data and is creating a static visualization to communicate that story clearly to an audience. This is common in reports and publications.\n",
        "* **Interactive Presentation**: A presentation that allows the end-user some degree of exploration within a guided framework, common on the web. Dashboards and interactive infographics are examples.\n",
        "\n",
        "---\n",
        "\n",
        "### **Chapter 2: Data Foundations**\n",
        "\n",
        "Since every visualization begins with data, this chapter examines the fundamental characteristics of data, its structure, and the common preprocessing steps required to make it suitable for visualization. Understanding your data is the first step to effective visualization.\n",
        "\n",
        "A typical dataset consists of a list of *n* records ($r_1, r_2, ..., r_n$), where each record $r_i$ is made up of *m* variables or observations ($v_1, v_2, ..., v_m$). Variables can be classified as **independent** (not affected by other variables, like time) or **dependent** (affected by other variables, like temperature at a given time and location). For example, in a weather dataset, time is independent, while temperature is dependent.\n",
        "\n",
        "---\n",
        "### **2.1 Types of Data**\n",
        "\n",
        "Data can be categorized based on its measurement type (ordinal vs. nominal) and its mathematical scale. This classification determines which visualizations and statistical analyses are appropriate.\n",
        "\n",
        "* **Ordinal (Numeric) Data**: This data consists of numeric values.\n",
        "    * **Binary**: Can only take values of 0 or 1. Example: pass/fail, yes/no.\n",
        "    * **Discrete**: Can only take integer values or values from a specific subset (e.g., (2, 4, 6)). Example: number of children in a family.\n",
        "    * **Continuous**: Represents real values within a given interval (e.g., [0, 5]). Example: height, temperature.\n",
        "\n",
        "* **Nominal (Non-numeric) Data**: This data consists of non-numeric values.\n",
        "    * **Categorical**: A value selected from a finite list of possibilities (e.g., 'red', 'blue', 'green'). Example: car brands, types of fruit.\n",
        "    * **Ranked**: A categorical variable that has a clear, implied ordering (e.g., 'small', 'medium', 'large'). Example: education level (high school, college, graduate).\n",
        "    * **Arbitrary**: A variable with a potentially infinite range of values with no implied ordering (e.g., street addresses). Example: names, ID numbers.\n",
        "\n",
        "* **Data Scale Attributes**: These attributes help further classify variables.\n",
        "    * **Ordering relation**: A property that allows the data to be sorted. All ordinal and ranked nominal variables have this property. Sorting is useful for bar charts and line graphs.\n",
        "    * **Distance metric**: A property that allows the distance between different records to be computed. This is present in all ordinal variables but generally not in nominal ones. For example, you can calculate the difference between two temperatures, but not between two colors.\n",
        "    * **Existence of absolute zero**: A property where a variable has a fixed lowest possible value. This helps differentiate types of ordinal data; for example, 'weight' has an absolute zero, while 'bank balance' (which can be negative) does not.\n",
        "\n",
        "The type of data determines the valid mathematical operations. For example, comparison operators (`<`, `>`) can only be applied to ranked nominal and ordinal data. Always check your data type before choosing a visualization or analysis method.\n",
        "\n",
        "---\n",
        "### **2.2 Structure within and between Records**\n",
        "\n",
        "Data sets have structure, both in their representation (syntax) and in the interrelationships between data items (semantics). Recognizing structure helps in choosing the right visualization and analysis techniques.\n",
        "\n",
        "* **2.2.1 Scalars, Vectors, and Tensors**\n",
        "    * A **scalar** is a single number in a data record, like the cost of an item. Example: temperature at a location.\n",
        "    * A **vector** is a composite item made of multiple values, like a 2D position `(x, y)` or a 3-component color `(R, G, B)`. Example: wind speed and direction.\n",
        "    * A **tensor** is a more general structure represented as an array or matrix. A scalar is a tensor of rank 0, and a vector is a tensor of rank 1. A rank M tensor in a D-dimensional space requires $D^M$ data values. Tensors are used in advanced scientific visualizations, such as stress analysis in engineering.\n",
        "\n",
        "* **2.2.2 Geometry and Grids**\n",
        "    * Geometric structure can be **explicit**, where coordinates are included for each data record (e.g., longitude and latitude for temperature sensors). This is common in geographic information systems (GIS).\n",
        "    * It can also be **implied**, where a grid structure is assumed, and successive records are located at successive grid locations (e.g., pixels in an image). Such grids can be uniform or **nonuniform/irregular**, where data is computed more densely in areas of high importance. For example, medical imaging often uses nonuniform grids to focus on areas of interest.\n",
        "\n",
        "* **2.2.3 Other Forms of Structure**\n",
        "    * **Timestamp**: An important attribute for time-oriented data, which can be relative or absolute. Time series visualizations rely on accurate timestamps.\n",
        "    * **Topology**: Describes how data records are connected. For example, vertices on a surface are connected by edges. This connectivity information is essential for processes like resampling and interpolation, and is crucial in network visualizations.\n",
        "\n",
        "---\n",
        "### **2.3 Data Preprocessing**\n",
        "\n",
        "Before visualization, raw data often needs to be cleaned, transformed, or reduced. Good preprocessing ensures accurate and meaningful visualizations.\n",
        "\n",
        "* **2.3.1 Metadata and Statistics**: Information *about* the data, known as **metadata**, provides crucial context like data formats, units, and what value signifies a missing entry. Basic statistics like the **mean** ($\\mu = \\frac{1}{n} \\sum_{i=0}^{n-1} x_i$) and **standard deviation** ($\\sigma = \\sqrt{\\frac{1}{n}\\sum(x_i - \\mu)^2}$) can provide useful insights and help detect outliers. Always check metadata before visualizing data.\n",
        "\n",
        "* **2.3.2 Missing Values and Data Cleansing**: Real-world data is often incomplete or erroneous. Common strategies to handle this include:\n",
        "    * **Discard the record**: The simplest but potentially most costly in terms of information loss. Use with caution.\n",
        "    * **Assign a sentinel value**: Use a designated value (e.g., -999) to mark missing entries, making them clearly visible in a visualization. This helps identify missing data but may affect analysis.\n",
        "    * **Assign the average value**: Replaces the missing entry with the mean for that variable. This minimally affects statistics but may mask interesting outliers.\n",
        "    * **Assign value based on nearest neighbor**: Find the most similar record based on other variables and use its value. This is useful for spatial or time series data.\n",
        "    * **Compute a substitute value**: Use advanced statistical methods, a process known as **imputation**, to generate a high-confidence substitute value. Imputation is common in machine learning.\n",
        "\n",
        "* **2.3.3 Normalization**: The process of transforming data to fit a particular statistical property, most commonly scaling values to the range of 0.0 to 1.0. This is crucial for mapping data to graphical attributes that have a fixed range (like color). Normalization helps compare variables with different units.\n",
        "    * **Linear Normalization**: $d_{normalized} = (d_{original} - d_{min}) / (d_{max} - d_{min})$. Use for evenly distributed data.\n",
        "    * **Non-linear Normalization**: For skewed distributions, a non-linear mapping like square root ($d_{sqrt-normalized} = (\\sqrt{d_{original}} - \\sqrt{d_{min}}) / (\\sqrt{d_{max}} - \\sqrt{d_{min}})$) or logarithmic ($d_{log-normalized} = (\\log d_{original} - \\log d_{min}) / (\\log d_{max} - \\log d_{min})$) may be more appropriate. Use for data with outliers or exponential growth.\n",
        "\n",
        "* **2.3.4 Segmentation**: The process of separating data into contiguous regions corresponding to a particular classification (e.g., an MRI scan segmented into bone, muscle, fat, and skin). This is often followed by an iterative **split-and-merge** refinement stage to improve the quality of the segments. Segmentation is key in image analysis and medical diagnostics.\n",
        "\n",
        "* **2.3.5 Sampling and Subsetting**: Transforming a dataset to a different spatial resolution. Sampling helps reduce data size and focus on important regions.\n",
        "    * **Interpolation**: Estimating values at locations between known samples.\n",
        "        * **Linear Interpolation**: Estimates a value at point C between points A and B using the formula: $d_C = d_A + (d_B - d_A) \\times (x_C - x_A) / (x_B - x_A)$. Use for simple, evenly spaced data.\n",
        "        * **Bilinear Interpolation**: Extends this to 2D by first interpolating horizontally between four grid points and then interpolating vertically using those results. Common in image processing.\n",
        "        * **Nonlinear Interpolation**: Uses higher-order polynomials like splines to create smoother transitions. The **Catmull-Rom curve** is a popular choice that ensures the curve passes through the data points. Use for smooth curves in graphics and animation.\n",
        "\n",
        "* **2.3.6 Dimension Reduction**: Techniques to reduce the dimensionality of data for visualization while preserving as much information as possible. Dimension reduction helps visualize complex, high-dimensional data.\n",
        "    * **Principal Component Analysis (PCA)**: A popular method that computes new dimensions (principal components) which are linear combinations of the originals. These new dimensions are sorted by how much they contribute to explaining the variance of the data. PCA is widely used in exploratory data analysis.\n",
        "    * **Multidimensional Scaling (MDS)**: A class of algorithms that finds a lower-dimensional representation of data that best preserves the inter-point distances from the original high-dimensional space. It iteratively adjusts point locations to minimize a **stress** function, which measures the discrepancy between distances in the high-D and low-D spaces. MDS is useful for visualizing similarity or dissimilarity between items.\n",
        "\n",
        "* **2.3.7 Mapping Nominal Dimensions to Numbers**: To visualize nominal (non-numeric) data, a mapping to a graphical attribute is needed that doesn't introduce artificial relationships. For variables with few distinct values, **color** and **shape** are good choices. For more complex cases, statistical techniques like **correspondence analysis** can be used to map nominal values to a numeric scale based on the similarity of the records associated with them. This enables visualization of categorical data in scatterplots and other charts.\n",
        "\n",
        "* **2.3.8 Aggregation and Summarization**: In cases of very large datasets, it's often useful to group similar data points and represent the group with a summary (e.g., count, average, extent) to reduce visual clutter and provide an overview. Aggregation is common in dashboards and big data analytics.\n",
        "\n",
        "* **2.3.9 Smoothing and Filtering**: A process, often done via **convolution**, that uses a weighted average of a point's neighbors to reduce noise and blur sharp discontinuities. A simple 1D smoothing formula is $p'_{i} = \\frac{p_{i-1}}{4} + \\frac{p_{i}}{2} + \\frac{p_{i+1}}{4}$. Smoothing is used in signal processing and time series analysis.\n",
        "\n",
        "* **2.3.10 Raster-to-Vector Conversion**: The process of extracting linear or polygonal structures from raster (pixel-based) data. This is useful for compression, comparison, and segmentation. Techniques include **thresholding**, **region-growing**, **boundary-detection** (using convolution), and **thinning**. Raster-to-vector conversion is important in geographic information systems and computer vision."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
